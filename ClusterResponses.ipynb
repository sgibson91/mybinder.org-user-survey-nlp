{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import nltk, string\n",
    "from nltk.corpus import stopwords\n",
    "import spacy  # you need to install the language model this way: python -m spacy download en_core_web_md\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "stop = stopwords.words(\"english\")\n",
    "\n",
    "exclude = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_to_centroid(vectors, centroid):\n",
    "    rank = [\n",
    "        [\n",
    "            x,\n",
    "            cosine_similarity(\n",
    "                centroid.reshape(1, -1), vectors[x].reshape(1, -1)\n",
    "            )[0][0],\n",
    "        ]\n",
    "        for x in range(len(vectors))\n",
    "    ]\n",
    "    rank.sort(key=lambda x: x[1], reverse=True)\n",
    "    closest = rank[:3]\n",
    "    return closest\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = \"\".join(ch for ch in text if ch not in exclude)\n",
    "    text = [x for x in nltk.word_tokenize(text) if x not in stop]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/mybinder.org-user-survey-feb-2020.csv\")\n",
    "\n",
    "answer_embs = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    answer = row[\n",
    "        \"If you could change one thing about Binder, what would it be?\"\n",
    "    ]\n",
    "    if type(answer) is str and len(answer) > 3:\n",
    "        answer_emb = nlp(answer).vector\n",
    "        answer_embs.append([index, answer, answer_emb])\n",
    "\n",
    "comment_words = \" \".join([x[1] for x in answer_embs])\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    width=800, height=800, background_color=\"white\", min_font_size=10\n",
    ").generate(comment_words)\n",
    "\n",
    "plt.figure(figsize=(8, 8), facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 10\n",
    "\n",
    "X = np.array([x[2] for x in answer_embs])\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "clusters = {\n",
    "    x: {\"centroid\": kmeans.cluster_centers_[x], \"answers\": [], \"vectors\": []}\n",
    "    for x in range(len(kmeans.cluster_centers_))\n",
    "}\n",
    "\n",
    "for x in range(len(answer_embs)):\n",
    "    answer = answer_embs[x][1]\n",
    "    vector = answer_embs[x][2]\n",
    "    label = kmeans.labels_[x]\n",
    "    clusters[label][\"answers\"].append(answer)\n",
    "    clusters[label][\"vectors\"].append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster, infos in clusters.items():\n",
    "    answers = infos[\"answers\"]\n",
    "    vectors = infos[\"vectors\"]\n",
    "    centroid = infos[\"centroid\"]\n",
    "    comment_words = [word for answer in answers for word in clean_text(answer)]\n",
    "    most_common = Counter(comment_words).most_common(5)\n",
    "    central_ids = get_closest_to_centroid(vectors, centroid)\n",
    "    central_answers = [answers[id_[0]] for id_ in central_ids]\n",
    "    for answ in central_answers:\n",
    "        print(answ)\n",
    "    print(\n",
    "        \"---> other\",\n",
    "        len(answers) - len(central_answers),\n",
    "        \"messages around the same topic\",\n",
    "    )\n",
    "\n",
    "    #    for answ in answers:\n",
    "    #        print (answ)\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query(q, text):\n",
    "    # if multiword query\n",
    "    if len(q.split(\" \")) > 1:\n",
    "        if q.lower() in answer.lower():\n",
    "            return True\n",
    "    else:\n",
    "        # we lowercase and remove puctuation\n",
    "        # then search for a perfect match\n",
    "        text = clean_text(text)\n",
    "        if q.lower() in text:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"R\"\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    answer = row[\n",
    "        \"If you could change one thing about Binder, what would it be?\"\n",
    "    ]\n",
    "    if type(answer) is str and len(answer) > 3:\n",
    "        check_relevance = search_query(q, answer)\n",
    "        if check_relevance is True:\n",
    "            print(answer + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37torch",
   "language": "python",
   "name": "py37torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
