{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing the February 2020 mybinder.org user survey responses\n",
    "\n",
    "From February to March 2020, the mybinder.org operating team ran a survey to collect feedback from our userbase.\n",
    "It comprised of three questions, two of which were multiple choice and the third was a free-form text response.\n",
    "The survey was advertised in a banner along the top of the mybinder.org homepage and was optional and anonymous to complete.\n",
    "The only data that was collected other than the responses to the questions were the date and time of survey completion.\n",
    "The free-form responses were checked for identifying features before being made available for analysis.\n",
    "\n",
    "This notebook analyses the responses from this survey using Natural Language Processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "stop = stopwords.words(\"english\")\n",
    "exclude = set(string.punctuation)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(123)  # Set a random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "resps = pd.read_csv(\n",
    "    \"data/mybinder.org-user-survey-feb-2020.csv\",\n",
    "    header=0,\n",
    "    names=[\"Timestamp\", \"Q1\", \"Q2\", \"Q3\"],\n",
    ")\n",
    "\n",
    "# Get questions for plot titles\n",
    "with open(\"data/mybinder.org-user-survey-feb-2020.csv\", \"r\") as f:\n",
    "    titles = f.readline().strip(\"\\n\").split('\"')\n",
    "\n",
    "titles = list(\n",
    "    filter(lambda a: a != \"\" and a != \",\" and a != \"Timestamp\", titles)\n",
    ")\n",
    "\n",
    "# Calculate total number of responses\n",
    "total_resps = len(resps)\n",
    "print(f\"Total number of responses to the survey: {total_resps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Would you recommend mybinder.org to a friend?\n",
    "\n",
    "This question is multiple choice: `Yes`, `No`, or `Maybe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the Yes/No/Maybe responses for Question 1\n",
    "bar_plot_dict = dict(Counter(resps[\"Q1\"]))\n",
    "\n",
    "# Remove NAN values\n",
    "try:\n",
    "    del bar_plot_dict[np.nan]\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "# Create a bar plot of results\n",
    "bar_plot_df = pd.Series(bar_plot_dict)\n",
    "bar_plot_df.sort_values(ascending=False, inplace=True)\n",
    "bar_plot_df.plot(kind=\"bar\", title=titles[0])\n",
    "\n",
    "# Calculate percentage\n",
    "percentages = 100 * (bar_plot_df.values / bar_plot_df.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. If you could change one thing about Binder, what would it be?\n",
    "\n",
    "This question was a free-form response and we've applied Natural Language Processing to identify commonly recurring words and topics from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some functions\n",
    "\n",
    "\n",
    "def get_closest_to_centroid(vectors, centroid):\n",
    "    \"\"\"Rank and return responses by closeness to centroid\"\"\"\n",
    "    rank = [\n",
    "        [\n",
    "            x,\n",
    "            cosine_similarity(\n",
    "                centroid.reshape(1, -1), vectors[x].reshape(1, -1)\n",
    "            )[0][0],\n",
    "        ]\n",
    "        for x in range(len(vectors))\n",
    "    ]\n",
    "\n",
    "    rank.sort(key=lambda x: x[1], reverse=True)\n",
    "    closest = rank[:3]\n",
    "\n",
    "    return closest\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean up the text responses\"\"\"\n",
    "    text = text.lower()\n",
    "    text = \"\".join(ch for ch in text if ch not in exclude)\n",
    "    text = [x for x in nltk.word_tokenize(text) if x not in stop]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and plot a word cloud from the responses\n",
    "answer_embs = []\n",
    "\n",
    "for index, row in resps.iterrows():\n",
    "    answer = row[\"Q2\"]\n",
    "    if type(answer) is str and len(answer) > 3:\n",
    "        answer_emb = nlp(answer).vector\n",
    "        answer_embs.append([index, answer, answer_emb])\n",
    "\n",
    "comment_words = \" \".join([x[1] for x in answer_embs])\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    width=800, height=800, background_color=\"white\", min_font_size=10\n",
    ").generate(comment_words)\n",
    "\n",
    "plt.figure(figsize=(8, 8), facecolor=None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find clusters of topics\n",
    "\n",
    "n_clusters = 10\n",
    "\n",
    "X = np.array([x[2] for x in answer_embs])\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "clusters = {\n",
    "    x: {\"centroid\": kmeans.cluster_centers_[x], \"answers\": [], \"vectors\": []}\n",
    "    for x in range(len(kmeans.cluster_centers_))\n",
    "}\n",
    "\n",
    "for x in range(len(answer_embs)):\n",
    "    answer = answer_embs[x][1]\n",
    "    vector = answer_embs[x][2]\n",
    "    label = kmeans.labels_[x]\n",
    "    clusters[label][\"answers\"].append(answer)\n",
    "    clusters[label][\"vectors\"].append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print answers closest to the centroid of the clustered topics\n",
    "\n",
    "for cluster, infos in clusters.items():\n",
    "    answers = infos[\"answers\"]\n",
    "    vectors = infos[\"vectors\"]\n",
    "    centroid = infos[\"centroid\"]\n",
    "\n",
    "    comment_words = [word for answer in answers for word in clean_text(answer)]\n",
    "    most_common = Counter(comment_words).most_common(5)\n",
    "    central_ids = get_closest_to_centroid(vectors, centroid)\n",
    "    central_answers = [answers[id_[0]] for id_ in central_ids]\n",
    "\n",
    "    for answ in central_answers:\n",
    "        print(answ, \"\\n\")\n",
    "\n",
    "    print(\n",
    "        \"---> other\",\n",
    "        len(answers) - len(central_answers),\n",
    "        \"messages around the same topic\",\n",
    "        \"\\n\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cells, a search query can be defined to return responses that mention a specific topic.\n",
    "In the example, the search term is for the R programming language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a search query function\n",
    "\n",
    "\n",
    "def search_query(q, text):\n",
    "    \"\"\"Search for a query within the text\"\"\"\n",
    "    # For multiword queries\n",
    "    if len(q.split(\" \")) > 1:\n",
    "        if q.lower() in answer.lower():\n",
    "            return True\n",
    "    else:\n",
    "        # Transform to lowercase and remove punctuation\n",
    "        # then search for a perfect match\n",
    "        text = clean_text(text)\n",
    "        if q.lower() in text:\n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it yourself!\n",
    "# Define a query below and re-run the cell\n",
    "query = \"R\"\n",
    "\n",
    "for index, row in resps.iterrows():\n",
    "    answer = row[\"Q2\"]\n",
    "\n",
    "    if (type(answer) is str) and (len(answer) > 3):\n",
    "        check_relevance = search_query(query, answer)\n",
    "        if check_relevance is True:\n",
    "            print(answer + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. What do you (mainly) use mybinder.org for?\n",
    "\n",
    "This question was multiple choice and the purpose is to identify how mybinder.org is being used by the community.\n",
    "The categories available for this question were:\n",
    "\n",
    "- Reproducible publishing\n",
    "- Pre-university teaching\n",
    "- University teaching\n",
    "- Workshops/training courses\n",
    "- Demos and talks\n",
    "- Documentation and examples\n",
    "- Sharing and collaborating with a team\n",
    "- Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count categorical responses to Question 3\n",
    "raw_dict = dict(Counter(resps[\"Q3\"]))\n",
    "\n",
    "# Remove NAN values\n",
    "try:\n",
    "    del raw_dict[np.nan]\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "# Filter out the defined categories\n",
    "categories = [key for key, value in raw_dict.items() if value >= 10]\n",
    "\n",
    "# Construct a dictionary with non-specified answers concatenated into \"Other\"\n",
    "concat_dict = {\"Other\": 0}\n",
    "for key, value in raw_dict.items():\n",
    "    if key in categories:\n",
    "        concat_dict[key] = value\n",
    "    else:\n",
    "        concat_dict[\"Other\"] += 1\n",
    "\n",
    "# Create pie plot of results\n",
    "concat_df = pd.Series(concat_dict)\n",
    "concat_df.sort_values(ascending=False, inplace=True)\n",
    "concat_df.plot(kind=\"pie\", title=titles[2])\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "# Calculate percentage\n",
    "percentages = 100 * (concat_df.values / concat_df.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
